import numpy as np
import scipy.sparse as sp 
import sklearn 
from sklearn.decomposition import PCA

from functools import wraps

def help() -> None:
    """
    A guidance on how to ask questions in the BioMANIA app.

    """  
    print(""" You can ask me questions like this!
    If you want to use SONATA to check whether ambiguity exist in your data, you can ask:
    1. Can you help me load the data I uploaded? My file is tmp/domain1.txt
    2. Can you help me check whether there is ambiguity in my data?
    3. Can you help me visualize the ambiguous groups?
    4. Please help me generate all self-ambiguity mapping matrices.

    If you want to visualize your input data, you can ask:
    1. Can you help me load the data I uploaded? My file is tmp/label_domain1.txt
    2. Could you please help me visualize the data domain based on its label?


    Then if you want to use SONATA to generate alternative solutions for a manifold aligner, firstly you can ask:
    1. Can you help me load the data I uploaded? My file is tmp/domain2.txt
    2. Please help me align the two data domains using SCOT.

    After that, you can visualize the alignment result by asking:
    1. Can you help me load the data I uploaded? My file is tmp/label_domain2.txt
    2. Can you help me visualize two domains aligned by SCOT with labels?

    Finally, you can ask SONATA to generate (and visualize) alternative solutions:
    1. Can you help me generate alternative mapping matrices for SCOT based on SONATA's self-ambiguity mapping matrices.
    2. Can you help me visualize the alternative mapping matrices for SCOT generated by SONATA based on labels?""")


# wrap two methods to avoid importing extra methods
def preserve_docstring(original_func):
    @wraps(original_func)
    def wrapper(*args, **kwargs):
        # Call the original function with all arguments and keyword arguments
        result = original_func(*args, **kwargs)
        return result
    return wrapper

#wrapped_normalize = preserve_docstring(sklearn.preprocessing.normalize)
def wrapped_normalize(X: np.ndarray, norm: str='l2', axis: int = 1) -> np.ndarray:
    """
    Normalize the input data array. Possible normalization types are 'l1', 'l2' and 'max'.

    Parameters
    ----------
    X : np.ndarray
        Input array to be normalized.
    norm : str
        Type of normalization to apply. Options: 'l1', 'l2', 'max'.
    axis : int, optional
        Axis along which the normalization is performed.
        Default is 1.

    Returns
    -------
    np.ndarray
        Normalized array.

    """
    return sklearn.preprocessing.normalize(X, norm, axis=axis)

def wrapped_pca(X: np.ndarray, n_components: int) -> np.ndarray:
    """
    Denoise the input data array by perform Principal Component Analysis (PCA).

    Parameters
    ----------
    X : np.ndarray
        The input data to be transformed.
    
    n_components : int
        The number of components to keep. This determines the dimensionality of
        the transformed data.

    Returns
    -------
    np.ndarray
        The transformed data, where each row represents a sample and each column
        represents a principal component.

    """
    pca_instance = PCA(n_components=n_components).fit(X)
    X_pca = pca_instance.fit_transform(X)
    return X_pca

def load_data(matrix_file: str) -> np.ndarray:
    """
    Load data from various file formats and return as a NumPy array.

    Parameters
    ----------
    matrix_file : str
        The path to the input matrix file.

    Returns
    -------
    np.ndarray
        The loaded data as a NumPy array.

    Notes
    -----
    This function supports loading data from different file formats, including 'txt', 'csv', 'npz', and 'npy'.
    It automatically detects the file format based on the file extension and returns the data as a NumPy array.

    """
    file_type = matrix_file.split('.')[-1]
    if file_type == 'txt':
        data = np.loadtxt(matrix_file)
    elif file_type == 'csv':
        data = np.loadtxt(matrix_file, delimiter=',')
    elif file_type == 'npz':
        data = sp.load_npz(matrix_file)
    else:
        data = np.load(matrix_file) 
    return data

def projection_barycentric(x: np.ndarray, y: np.ndarray, coupling: np.ndarray, XontoY: bool = True) -> tuple:
    """
    Perform barycentric projection. This function projects points from two datasets (x and y) 
    onto a common coordinate system based on an alignment mapping

    Parameters
    ----------
    x : numpy.ndarray
        The data points in the source domain.
    y : numpy.ndarray
        The data points in the target domain.
    coupling : numpy.ndarray
        The alignment coupling matrix representing the relationship between domains.
    XontoY : bool, optional
        Flag indicating the direction of projection, by default True (X onto Y).

    Returns
    -------
    tuple
        A tuple containing two arrays (X_aligned and Y_aligned) representing the projected data in the target domain.

    Notes
    -----
    This function performs barycentric projection from one domain to another based on the coupling matrix.
    It can project the first domain onto the second domain (XontoY=True) or vice versa (XontoY=False).

    projection function from SCOT: https://github.com/rsinghlab/SCOT
    """
    if XontoY:
        #Projecting the first domain onto the second domain
        y_aligned=y
        weights=np.sum(coupling, axis = 0)
        X_aligned=np.matmul(coupling, y) / weights[:, None]
    else:
        #Projecting the second domain onto the first domain
        X_aligned = x
        weights=np.sum(coupling, axis = 0)
        y_aligned=np.matmul(np.transpose(coupling), x) / weights[:, None]

    return X_aligned, y_aligned